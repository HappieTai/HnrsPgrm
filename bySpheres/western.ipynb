{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db67ba19-129b-4485-b5f8-7737f1eb8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "def pdf_extract(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "ger = pdf_extract('germany/germany_7.pdf') + \" \" + pdf_extract('germany/germany_81.pdf') + \" \" + pdf_extract('germany/germany_82.pdf')+ \" \"+ pdf_extract('germany/germany_83.pdf')\n",
    "spain = pdf_extract('spain/spain_7.pdf')+\" \"+pdf_extract('spain/spain_71.pdf')+\" \"+pdf_extract('spain/spain_72.pdf')+\" \"+pdf_extract('spain/spain_8.pdf')+\" \"+pdf_extract('spain/spain_9.pdf')\n",
    "aus = pdf_extract('australia/australia.pdf')\n",
    "phili = pdf_extract('phillipeans/Phili_7.pdf') +\" \"+pdf_extract('phillipeans/phili_8.pdf')+\" \"+pdf_extract('phillipeans/Phili_9.pdf')\n",
    "uk = pdf_extract('UK/UK_7.pdf')+\" \"+pdf_extract('UK/UK_8.pdf')+\" \"+pdf_extract('UK/UK_9.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e0eb76-c444-4655-a00e-c71efa2b5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbooks = [ger, spain, phili,uk, aus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698d9f-9282-4938-9e6b-bdbbb58f3707",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c731351b-f590-47fd-a2da-141307297ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048f653e-08fd-4854-9363-111be2beac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(post):\n",
    "    if detect(post) != 'en':\n",
    "        return ''\n",
    "    # Make posts lowercase\n",
    "    post = post.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    post = re.sub(r'[^a-zA-Z\\s]', ' ', post)\n",
    "    \n",
    "    # Remove words with repeated letters\n",
    "    #post = re.sub(r'([a-zA-Z])\\1+', r'\\1', post)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(post)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26899fb3-3fcb-4e08-a820-846fc13be753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTextbooks = []\n",
    "for i in textbooks:\n",
    "    cleanTextbooks.append(clean_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0865f5-c5a6-4171-b347-e2f7d84c1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These have spaces, we use these to select the male and female words\n",
    "menWords = [\" man \", \" boy \", \" male \", \" brother \", \" father \", \" son \", \" husband \", \" king \", \" prince \", \" uncle \", \" nephew \", \" he \", \" him \", \" his \", \" gentleman \", \" sir \", \" mr. \", \" hero \", \" lord \", \" patriarch \", \" men \"]\n",
    "womenWords = [\" woman \", \" girl \", \" female \", \" sister \", \" mother \", \" daughter \", \" wife \", \" queen \", \" princess \", \" aunt \", \" niece \", \" she \", \" her \", \" hers \", \" lady \", \" ma'am \",\" madam \", \" mrs. \", \" ms. \", \" miss \", \" heroine \", \" dame \", \" matriarch \", \" women \"]\n",
    "#These have no spaces, so these can be used to throw away words during TFIDF\n",
    "menWordsNoSpace = [\"man\", \"boy\", \"male\", \"brother\", \"father\", \"son\", \"husband\", \"king\", \"prince\", \"uncle\", \"nephew\", \"he\", \"him\", \"his\", \"gentleman\", \"sir\", \"mr\", \"hero\", \"lord\", \"patriarch\", \"men\"]\n",
    "womenWordsNoSpace = [\"woman\", \"girl\", \"female\", \"sister\", \"mother\", \"daughter\", \"wife\", \"queen\", \"princess\", \"aunt\", \"niece\", \"she\", \"her\", \"hers\", \"lady\", \"ma'am\",\"madam\", \"mrs\", \"heroine\", \"dame\", \"matriarch\", \"women\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "290d69e4-4333-40ca-87ba-568c25c479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "menPara = [[] for _ in range(5)]\n",
    "womenPara = [[] for _ in range(5)]\n",
    "for i in range(0, 5):\n",
    "    text = cleanTextbooks[i]\n",
    "    paragraphs = [text[j:j+100] for j in range(0, len(text), 100)]\n",
    "    for paragraph in paragraphs:\n",
    "        for j in menWords:\n",
    "            if j in paragraph:\n",
    "                menPara[i].append(paragraph)\n",
    "        for j in womenWords:\n",
    "            if j in paragraph:\n",
    "                womenPara[i].append(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244f6af-3406-4451-90f3-cc6888590dcc",
   "metadata": {},
   "source": [
    "# Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2334899-c275-4195-8f8a-e04226d6e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567\n",
      "1078\n"
     ]
    }
   ],
   "source": [
    "men_count = sum(len(sublist) for sublist in menPara)\n",
    "print(men_count)\n",
    "women_count = sum(len(sublist) for sublist in womenPara)\n",
    "print(women_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2fb31-e585-4ab5-b235-8fef226dbcba",
   "metadata": {},
   "source": [
    "# Firstness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc06c38f-9e71-45fe-8d94-c76c27ae5545",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 [('aunt', 'uncle'), ('mother', 'father'), ('mother', 'father'), ('woman', 'hero'), ('girl', 'boy'), ('girl', 'boy'), ('aunt', 'uncle'), ('mother', 'father'), ('mother', 'father'), ('mother', 'father'), ('girl', 'brother'), ('lady', 'brother'), ('women', 'men'), ('mother', 'father'), ('mother', 'brother'), ('mother', 'mr'), ('wife', 'brother'), ('sister', 'son'), ('mother', 'son'), ('mother', 'son'), ('mother', 'son'), ('mother', 'son'), ('mother', 'son'), ('mother', 'son'), ('sister', 'brother'), ('daughter', 'father'), ('daughter', 'father'), ('princess', 'king'), ('princess', 'king'), ('mother', 'father'), ('girl', 'mr'), ('wife', 'boy'), ('mother', 'father'), ('sister', 'brother'), ('mother', 'father'), ('sister', 'husband'), ('sister', 'brother'), ('niece', 'nephew'), ('niece', 'nephew'), ('niece', 'brother'), ('niece', 'nephew'), ('wife', 'mr'), ('wife', 'mr'), ('wife', 'mr'), ('female', 'male')]\n"
     ]
    }
   ],
   "source": [
    "femaleFirst = []\n",
    "for sublist in womenPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1): \n",
    "                if words[i].lower() in womenWordsNoSpace and words[i + 1].lower() in menWordsNoSpace:\n",
    "                    femaleFirst.append((words[i], words[i + 1]))\n",
    "print(len(femaleFirst),femaleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b2b3f0a-1032-438d-a825-8a96727a06ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 [('men', 'women'), ('men', 'women'), ('brother', 'sister'), ('brother', 'sister'), ('brother', 'sister'), ('uncle', 'aunt'), ('uncle', 'aunt'), ('father', 'daughter'), ('father', 'daughter'), ('male', 'female'), ('man', 'woman'), ('man', 'woman'), ('nephew', 'niece'), ('brother', 'sister'), ('men', 'women'), ('brother', 'sister'), ('men', 'women'), ('uncle', 'aunt'), ('brother', 'sister'), ('man', 'woman'), ('man', 'woman'), ('men', 'women'), ('husband', 'wife'), ('husband', 'wife'), ('men', 'women'), ('men', 'women'), ('men', 'women'), ('son', 'daughter'), ('men', 'women'), ('men', 'women'), ('king', 'queen'), ('nephew', 'sister'), ('nephew', 'sister'), ('son', 'daughter'), ('father', 'daughter'), ('man', 'mrs'), ('father', 'mrs'), ('father', 'mrs'), ('man', 'woman'), ('sir', 'mrs'), ('sir', 'mrs'), ('male', 'female'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('king', 'queen'), ('king', 'queen'), ('king', 'queen'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('lord', 'lady'), ('father', 'mother'), ('men', 'women'), ('men', 'women'), ('man', 'woman'), ('father', 'daughter'), ('father', 'daughter'), ('men', 'women'), ('men', 'women'), ('men', 'women'), ('male', 'female'), ('father', 'mother'), ('male', 'female'), ('male', 'female'), ('male', 'female')]\n"
     ]
    }
   ],
   "source": [
    "maleFirst = []\n",
    "for sublist in menPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1):  \n",
    "                if words[i].lower() in menWordsNoSpace and words[i + 1].lower() in womenWordsNoSpace:\n",
    "                    maleFirst.append((words[i], words[i + 1]))\n",
    "print(len(maleFirst),maleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af37994e-05be-412d-9bb3-04d6d55624ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameLevel = {\n",
    "    \"siblings\": {\"brother\", \"sister\"},\n",
    "    \"parent_child\": {\"father\", \"mother\", \"son\", \"daughter\"},\n",
    "    \"spouses\": {\"husband\", \"wife\"},\n",
    "    \"royalty\": {\"king\", \"queen\", \"prince\", \"princess\"},\n",
    "    \"extended_family\": {\"uncle\", \"aunt\", \"nephew\", \"niece\"},\n",
    "    \"personal_pronouns\": {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"},\n",
    "    \"titles\": {\"gentleman\", \"lady\", \"sir\", \"ma'am\", \"mr\", \"mrs\", \"madam\"},\n",
    "    \"heroic_roles\": {\"hero\", \"heroine\"},\n",
    "    \"social_roles\": {\"patriarch\", \"matriarch\"},\n",
    "    \"general_plural\": {\"men\", \"women\"},\n",
    "}\n",
    "flat = {word for group in sameLevel.values() for word in group}\n",
    "def isSame(pair):\n",
    "    return pair[0] in flat and pair[1] in flat\n",
    "femaleFirst = [pair for pair in femaleFirst if isSame(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfbab8b1-a034-45fb-b4bb-ed631ff7bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "maleFirst = [pair for pair in maleFirst if isSame(pair)]\n",
    "print(len(maleFirst))\n",
    "print(len(femaleFirst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42749a-7ebd-4437-a0c0-41fc656e0b60",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bb0da50-bff0-4643-8b34-a47567b2d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.097, 'neu': 0.728, 'pos': 0.175, 'compound': 1.0} {'neg': 0.1, 'neu': 0.723, 'pos': 0.177, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "fscores = analyzer.polarity_scores(fw)\n",
    "mscores = analyzer.polarity_scores(fm)\n",
    "print(fscores,mscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f4b6-b38a-4060-b0d6-6cb38e185d86",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b92c3597-3e9b-43c2-9309-060dc953377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46939507-4cb2-4878-bf59-dd490ff40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_nested_list(nested_list):\n",
    "    return [\n",
    "        [\n",
    "            ' '.join(stemmer.stem(word) for word in sentence.split())\n",
    "            for sentence in sublist\n",
    "        ]\n",
    "        for sublist in nested_list\n",
    "    ]\n",
    "menParaOriginal = menPara\n",
    "womenParaOriginal = womenPara\n",
    "menPara = stem_nested_list(menPara)\n",
    "womenPara = stem_nested_list(womenPara)\n",
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0455810b-6118-4b49-9f9b-fad88d160e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobeTFIDF = [\" \".join(\" \".join(row) for row in menPara),\" \".join(\" \".join(row) for row in womenPara)]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tobeTFIDF)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_tfidf = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41496c61-bcae-47b8-bd80-93cd15193b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of female words\n",
    "doc_index = 1\n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores = sorted(word_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_fs = sorted_word_scores[:300]\n",
    "top_300_words_f = [word for word, score in sorted_word_scores[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3180e23a-9366-4c8a-8ea8-7f0614e5a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of male words\n",
    "doc_index = 0  \n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs_m = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores_m = sorted(word_score_pairs_m, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_ms = sorted_word_scores_m[:300]\n",
    "top_300_words_m = [word for word, score in sorted_word_scores_m[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7caf800-9276-4c28-b948-7fe71e47ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove common words and gendered keywords\n",
    "common = list(set(top_300_words_f) & set(top_300_words_m))\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in common]\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in womenWordsNoSpace]\n",
    "female_300 = \" \".join(top_300_words_f)\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in common]\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in menWordsNoSpace]\n",
    "male_300 = \" \".join(top_300_words_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359c200d-8b7e-4d88-9768-d95d1ecf33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stevenson children nona rosi door eat sit wear oper partner drive ex past cook dress someon student buy guess number point stand correct bad exampl felt hair kid near seem black booli care expect form law pictur tomorrow verb draw drink enjoy femal hard hate st today week worri eight maori babi beauti bu cours danc ed exam food forsyth lesson niec ok second seen tonight angela selena choos cloth continu convers eddi experi eye fall french fun grandmoth half hurt\n",
      "arthur lawrenc princ uncl dead sword bediver god modr lucan knight age need dream kill shall water montagu bodi morn yet upon bernard charley summer cri tybalt teacher john studi gawain order poem took becom big light martin noth open track act earth jesu labang pass ring seven show yeah ala hermit arm head hold lam land line met bring host howard messag servant epic spear bed escalu field gave luther meet quickli scene set side stay street unto york alaska\n"
     ]
    }
   ],
   "source": [
    "print(female_300)\n",
    "print(male_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02bb46d5-079f-4682-8bb8-a609b125e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "mwords = male_300.split()\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb6e9164-4aaf-4e46-9cb0-818099905043",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwords = female_300.split()\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad186a1a-666b-4bc3-89f8-fb43847cfc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Male Words: [('arthur', 1), ('lawrenc', 1), ('princ', 1), ('uncl', 1), ('dead', 1), ('sword', 1), ('bediver', 1), ('god', 1), ('modr', 1), ('lucan', 1), ('knight', 1), ('age', 1), ('need', 1), ('dream', 1), ('kill', 1), ('shall', 1), ('water', 1), ('montagu', 1), ('bodi', 1), ('morn', 1), ('yet', 1), ('upon', 1), ('bernard', 1), ('charley', 1), ('summer', 1), ('cri', 1), ('tybalt', 1), ('teacher', 1), ('john', 1), ('studi', 1), ('gawain', 1), ('order', 1), ('poem', 1), ('took', 1), ('becom', 1), ('big', 1), ('light', 1), ('martin', 1), ('noth', 1), ('open', 1)]\n",
      "Top 40 Female Words: [('stevenson', 1), ('children', 1), ('nona', 1), ('rosi', 1), ('door', 1), ('eat', 1), ('sit', 1), ('wear', 1), ('oper', 1), ('partner', 1), ('drive', 1), ('ex', 1), ('past', 1), ('cook', 1), ('dress', 1), ('someon', 1), ('student', 1), ('buy', 1), ('guess', 1), ('number', 1), ('point', 1), ('stand', 1), ('correct', 1), ('bad', 1), ('exampl', 1), ('felt', 1), ('hair', 1), ('kid', 1), ('near', 1), ('seem', 1), ('black', 1), ('booli', 1), ('care', 1), ('expect', 1), ('form', 1), ('law', 1), ('pictur', 1), ('tomorrow', 1), ('verb', 1), ('draw', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Example word lists (assuming male_300 and female_300 are defined as strings)\n",
    "mwords = male_300.split()  # Male words\n",
    "fwords = female_300.split()  # Female words\n",
    "\n",
    "# Filtered words for male\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)\n",
    "print(\"Top 40 Male Words:\", topMwords)\n",
    "\n",
    "# Filtered words for female\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)\n",
    "print(\"Top 40 Female Words:\", topFwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9f779-7f69-4213-91cf-3429f1446bbf",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbdfc427-8744-4c54-ba73-fc4c9820b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Female:\n",
      "         Word  FemaleImportance\n",
      "2900     issu               1.0\n",
      "4789  rooster               1.0\n",
      "201    angela               1.0\n",
      "4246  phillip               1.0\n",
      "4982   selena               1.0\n",
      "1670    eight               1.0\n",
      "5776     tina               1.0\n",
      "3861     nona               1.0\n",
      "4797     rosi               1.0\n",
      "3491  marriag               1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 1]  # Probability of being female\n",
    "female_contributions = np.dot(X.T.toarray(), proba)\n",
    "female_importance = female_contributions / np.sum(X.toarray(), axis=0)\n",
    "female_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"FemaleImportance\": female_importance\n",
    "}).sort_values(by=\"FemaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Female:\")\n",
    "print(female_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41e753bf-6df0-45a0-8ec0-d4b191ff4127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Male:\n",
      "          Word  MaleImportance\n",
      "2193    gawain             1.0\n",
      "5300     spare             1.0\n",
      "633       boat             1.0\n",
      "6202      waig             1.0\n",
      "220        ant             1.0\n",
      "6198    wagner             1.0\n",
      "2509    hermit             1.0\n",
      "5452  strength             1.0\n",
      "1408   destini             1.0\n",
      "3091    knight             1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 0]  # Probability of being male (class 0)\n",
    "\n",
    "\n",
    "male_contributions = np.dot(X.T.toarray(), proba)\n",
    "male_importance = male_contributions / np.sum(X.toarray(), axis=0)\n",
    "male_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"MaleImportance\": male_importance\n",
    "}).sort_values(by=\"MaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Male:\")\n",
    "print(male_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65eaaecb-a8fb-489c-b839-8eb044ce9925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sungen',\n",
       " 'sungen',\n",
       " 'sungen',\n",
       " 'aboriginal',\n",
       " 'aboriginal',\n",
       " 'aboriginal',\n",
       " 'aboriginal',\n",
       " 'cass',\n",
       " 'cass',\n",
       " 'cass',\n",
       " 'cass']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menParaOriginal for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenParaOriginal for item in sublist]))\n",
    "ps = PorterStemmer()\n",
    "words = word_tokenize(fw)\n",
    "matching = [word for word in words if ps.stem(word) in {\"cass\", \"aborigin\",\"sungen\"}]\n",
    "matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
