{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db67ba19-129b-4485-b5f8-7737f1eb8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "def pdf_extract(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "ssu = pdf_extract('Ssudan/ssudan_7.pdf')+\" \"+pdf_extract('Ssudan/ssudan_8.pdf')+\" \"+pdf_extract('Ssudan/ssudan_9.pdf')\n",
    "eth = pdf_extract('ethiopia/eth_7.pdf') + \" \" + pdf_extract('ethiopia/eth_8.pdf') + \" \" + pdf_extract('ethiopia/eth_9.pdf')\n",
    "sa = pdf_extract('southAfri/sa_7.pdf')+\" \"+pdf_extract('southAfri/sa_9.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e0eb76-c444-4655-a00e-c71efa2b5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbooks = [ssu,eth,sa]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698d9f-9282-4938-9e6b-bdbbb58f3707",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c731351b-f590-47fd-a2da-141307297ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048f653e-08fd-4854-9363-111be2beac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(post):\n",
    "    if detect(post) != 'en':\n",
    "        return ''\n",
    "    # Make posts lowercase\n",
    "    post = post.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    post = re.sub(r'[^a-zA-Z\\s]', ' ', post)\n",
    "    \n",
    "    # Remove words with repeated letters\n",
    "    #post = re.sub(r'([a-zA-Z])\\1+', r'\\1', post)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(post)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26899fb3-3fcb-4e08-a820-846fc13be753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTextbooks = []\n",
    "for i in textbooks:\n",
    "    cleanTextbooks.append(clean_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0865f5-c5a6-4171-b347-e2f7d84c1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These have spaces, we use these to select the male and female words\n",
    "menWords = [\" man \", \" boy \", \" male \", \" brother \", \" father \", \" son \", \" husband \", \" king \", \" prince \", \" uncle \", \" nephew \", \" he \", \" him \", \" his \", \" gentleman \", \" sir \", \" mr. \", \" hero \", \" lord \", \" patriarch \", \" men \"]\n",
    "womenWords = [\" woman \", \" girl \", \" female \", \" sister \", \" mother \", \" daughter \", \" wife \", \" queen \", \" princess \", \" aunt \", \" niece \", \" she \", \" her \", \" hers \", \" lady \", \" ma'am \",\" madam \", \" mrs. \", \" ms. \", \" miss \", \" heroine \", \" dame \", \" matriarch \", \" women \"]\n",
    "#These have no spaces, so these can be used to throw away words during TFIDF\n",
    "menWordsNoSpace = [\"man\", \"boy\", \"male\", \"brother\", \"father\", \"son\", \"husband\", \"king\", \"prince\", \"uncle\", \"nephew\", \"he\", \"him\", \"his\", \"gentleman\", \"sir\", \"mr\", \"hero\", \"lord\", \"patriarch\", \"men\"]\n",
    "womenWordsNoSpace = [\"woman\", \"girl\", \"female\", \"sister\", \"mother\", \"daughter\", \"wife\", \"queen\", \"princess\", \"aunt\", \"niece\", \"she\", \"her\", \"hers\", \"lady\", \"ma'am\",\"madam\", \"mrs\", \"heroine\", \"dame\", \"matriarch\", \"women\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290d69e4-4333-40ca-87ba-568c25c479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "menPara = [[] for _ in range(3)]\n",
    "womenPara = [[] for _ in range(3)]\n",
    "for i in range(0, 3):\n",
    "    text = cleanTextbooks[i]\n",
    "    paragraphs = [text[j:j+100] for j in range(0, len(text), 100)]\n",
    "    for paragraph in paragraphs:\n",
    "        for j in menWords:\n",
    "            if j in paragraph:\n",
    "                menPara[i].append(paragraph)\n",
    "        for j in womenWords:\n",
    "            if j in paragraph:\n",
    "                womenPara[i].append(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244f6af-3406-4451-90f3-cc6888590dcc",
   "metadata": {},
   "source": [
    "# Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2334899-c275-4195-8f8a-e04226d6e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728\n",
      "608\n"
     ]
    }
   ],
   "source": [
    "men_count = sum(len(sublist) for sublist in menPara)\n",
    "print(men_count)\n",
    "women_count = sum(len(sublist) for sublist in womenPara)\n",
    "print(women_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2fb31-e585-4ab5-b235-8fef226dbcba",
   "metadata": {},
   "source": [
    "# Firstness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc06c38f-9e71-45fe-8d94-c76c27ae5545",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 [('women', 'men'), ('mother', 'father'), ('mother', 'father'), ('women', 'men'), ('sister', 'uncle'), ('women', 'men'), ('girl', 'father'), ('girl', 'father'), ('mother', 'father'), ('mother', 'father'), ('wife', 'husband'), ('woman', 'husband'), ('women', 'men'), ('wife', 'son'), ('daughter', 'brother'), ('wife', 'son'), ('daughter', 'brother'), ('wife', 'son'), ('daughter', 'brother'), ('wife', 'son'), ('daughter', 'brother'), ('woman', 'man'), ('girl', 'boy'), ('wife', 'husband'), ('sister', 'brother'), ('daughter', 'son'), ('woman', 'man'), ('girl', 'boy'), ('wife', 'husband'), ('sister', 'brother'), ('daughter', 'son'), ('woman', 'man'), ('girl', 'boy'), ('wife', 'husband'), ('sister', 'brother'), ('daughter', 'son'), ('woman', 'man'), ('girl', 'boy'), ('wife', 'husband'), ('sister', 'brother'), ('daughter', 'son'), ('woman', 'man'), ('girl', 'boy'), ('wife', 'husband'), ('sister', 'brother'), ('daughter', 'son'), ('woman', 'man'), ('girl', 'boy'), ('wife', 'husband'), ('sister', 'brother'), ('daughter', 'son'), ('girl', 'man'), ('wife', 'husband'), ('wife', 'husband')]\n"
     ]
    }
   ],
   "source": [
    "femaleFirst = []\n",
    "for sublist in womenPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1): \n",
    "                if words[i].lower() in womenWordsNoSpace and words[i + 1].lower() in menWordsNoSpace:\n",
    "                    femaleFirst.append((words[i], words[i + 1]))\n",
    "print(len(femaleFirst),femaleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2b3f0a-1032-438d-a825-8a96727a06ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 [('boy', 'mother'), ('sir', 'madam'), ('sir', 'madam'), ('sir', 'madam'), ('father', 'girl'), ('man', 'woman'), ('men', 'women'), ('brother', 'sister'), ('brother', 'sister'), ('father', 'daughter'), ('father', 'daughter'), ('brother', 'sister'), ('husband', 'wife'), ('men', 'women'), ('man', 'woman'), ('man', 'woman'), ('man', 'woman'), ('men', 'women'), ('men', 'women'), ('men', 'women'), ('sir', 'madam'), ('men', 'women'), ('men', 'women'), ('men', 'women'), ('boy', 'girl'), ('brother', 'sister'), ('brother', 'sister'), ('men', 'women'), ('husband', 'wife'), ('brother', 'sister'), ('man', 'wife'), ('man', 'wife'), ('husband', 'daughter'), ('man', 'woman'), ('brother', 'sister'), ('brother', 'wife'), ('brother', 'sister'), ('brother', 'wife'), ('brother', 'sister'), ('brother', 'wife'), ('man', 'woman'), ('son', 'daughter'), ('son', 'daughter'), ('man', 'girl'), ('man', 'girl'), ('boy', 'wife'), ('father', 'mother'), ('brother', 'daughter'), ('man', 'girl'), ('boy', 'wife'), ('father', 'mother'), ('brother', 'daughter'), ('man', 'girl'), ('boy', 'wife'), ('father', 'mother'), ('brother', 'daughter'), ('man', 'girl'), ('boy', 'wife'), ('father', 'mother'), ('brother', 'daughter'), ('man', 'girl'), ('boy', 'wife'), ('father', 'mother'), ('brother', 'daughter'), ('man', 'girl'), ('boy', 'wife'), ('father', 'mother'), ('brother', 'daughter'), ('sir', 'woman'), ('men', 'woman'), ('sir', 'madam'), ('sir', 'madam'), ('boy', 'girl'), ('man', 'woman'), ('man', 'woman')]\n"
     ]
    }
   ],
   "source": [
    "maleFirst = []\n",
    "for sublist in menPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1):  \n",
    "                if words[i].lower() in menWordsNoSpace and words[i + 1].lower() in womenWordsNoSpace:\n",
    "                    maleFirst.append((words[i], words[i + 1]))\n",
    "print(len(maleFirst),maleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af37994e-05be-412d-9bb3-04d6d55624ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameLevel = {\n",
    "    \"siblings\": {\"brother\", \"sister\"},\n",
    "    \"parent_child\": {\"father\", \"mother\", \"son\", \"daughter\"},\n",
    "    \"spouses\": {\"husband\", \"wife\"},\n",
    "    \"royalty\": {\"king\", \"queen\", \"prince\", \"princess\"},\n",
    "    \"extended_family\": {\"uncle\", \"aunt\", \"nephew\", \"niece\"},\n",
    "    \"personal_pronouns\": {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"},\n",
    "    \"titles\": {\"gentleman\", \"lady\", \"sir\", \"ma'am\", \"mr\", \"mrs\", \"madam\"},\n",
    "    \"heroic_roles\": {\"hero\", \"heroine\"},\n",
    "    \"social_roles\": {\"patriarch\", \"matriarch\"},\n",
    "    \"general_plural\": {\"men\", \"women\"},\n",
    "}\n",
    "flat = {word for group in sameLevel.values() for word in group}\n",
    "def isSame(pair):\n",
    "    return pair[0] in flat and pair[1] in flat\n",
    "femaleFirst = [pair for pair in femaleFirst if isSame(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbab8b1-a034-45fb-b4bb-ed631ff7bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "maleFirst = [pair for pair in maleFirst if isSame(pair)]\n",
    "print(len(maleFirst))\n",
    "print(len(femaleFirst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42749a-7ebd-4437-a0c0-41fc656e0b60",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bb0da50-bff0-4643-8b34-a47567b2d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.066, 'neu': 0.776, 'pos': 0.158, 'compound': 1.0} {'neg': 0.091, 'neu': 0.758, 'pos': 0.152, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "fscores = analyzer.polarity_scores(fw)\n",
    "mscores = analyzer.polarity_scores(fm)\n",
    "print(fscores,mscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f4b6-b38a-4060-b0d6-6cb38e185d86",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92c3597-3e9b-43c2-9309-060dc953377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46939507-4cb2-4878-bf59-dd490ff40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_nested_list(nested_list):\n",
    "    return [\n",
    "        [\n",
    "            ' '.join(stemmer.stem(word) for word in sentence.split())\n",
    "            for sentence in sublist\n",
    "        ]\n",
    "        for sublist in nested_list\n",
    "    ]\n",
    "menParaOriginal = menPara\n",
    "womenParaOriginal = womenPara\n",
    "menPara = stem_nested_list(menPara)\n",
    "womenPara = stem_nested_list(womenPara)\n",
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0455810b-6118-4b49-9f9b-fad88d160e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobeTFIDF = [\" \".join(\" \".join(row) for row in menPara),\" \".join(\" \".join(row) for row in womenPara)]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tobeTFIDF)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_tfidf = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41496c61-bcae-47b8-bd80-93cd15193b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of female words\n",
    "doc_index = 1\n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores = sorted(word_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_fs = sorted_word_scores[:300]\n",
    "top_300_words_f = [word for word, score in sorted_word_scores[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3180e23a-9366-4c8a-8ea8-7f0614e5a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of male words\n",
    "doc_index = 0  \n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs_m = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores_m = sorted(word_score_pairs_m, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_ms = sorted_word_scores_m[:300]\n",
    "top_300_words_m = [word for word, score in sorted_word_scores_m[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7caf800-9276-4c28-b948-7fe71e47ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove common words and gendered keywords\n",
    "common = list(set(top_300_words_f) & set(top_300_words_m))\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in common]\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in womenWordsNoSpace]\n",
    "female_300 = \" \".join(top_300_words_f)\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in common]\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in menWordsNoSpace]\n",
    "male_300 = \" \".join(top_300_words_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "359c200d-8b7e-4d88-9768-d95d1ecf33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dawit child peter ladi coffe discuss class done femal hope milk today enough sudan atieno chang hear hospit jack lesson mobil partner prepar babi beauti birthday cotton find harri shop st market xavier differ eat flat groom howev lot mr opinion pregnant present sugar travel wash karl smart spider teach compar dinner eye glass import law mean much phone photo practic tomorrow briefcas ch coupl meseret bad born care cat chair cindi cultur daddi danc dog dress dri ed happi hello keep kiss la learner member mine offic plant respect sat seen shout sing uniform wa accid\n",
      "uncl fi luther okonkwo martin usual abraham run unoka god ill yalla yam dead er pm sampson barn given harvest maureen tear tree villag week mandela nwakibi wizard anoth countri equal five jr put back cloth face join lost met nation possess saw true bite fight pen ali anim bull carri continu farm flower heard holiday hyena indb ing laugh leav sb someth war abl aster cave civil consult hundr kanja neither sea sens short suddenli accept accord afraid ago allow becom cattl check describ drink drive final gregori hors jean jump let maman\n"
     ]
    }
   ],
   "source": [
    "print(female_300)\n",
    "print(male_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02bb46d5-079f-4682-8bb8-a609b125e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "mwords = male_300.split()\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb6e9164-4aaf-4e46-9cb0-818099905043",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwords = female_300.split()\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad186a1a-666b-4bc3-89f8-fb43847cfc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Male Words: [('uncl', 1), ('fi', 1), ('luther', 1), ('okonkwo', 1), ('martin', 1), ('usual', 1), ('abraham', 1), ('run', 1), ('unoka', 1), ('god', 1), ('ill', 1), ('yalla', 1), ('yam', 1), ('dead', 1), ('er', 1), ('pm', 1), ('sampson', 1), ('barn', 1), ('given', 1), ('harvest', 1), ('maureen', 1), ('tear', 1), ('tree', 1), ('villag', 1), ('week', 1), ('mandela', 1), ('nwakibi', 1), ('wizard', 1), ('anoth', 1), ('countri', 1), ('equal', 1), ('five', 1), ('jr', 1), ('put', 1), ('back', 1), ('cloth', 1), ('face', 1), ('join', 1), ('lost', 1), ('met', 1)]\n",
      "Top 40 Female Words: [('dawit', 1), ('child', 1), ('peter', 1), ('ladi', 1), ('coffe', 1), ('discuss', 1), ('class', 1), ('done', 1), ('femal', 1), ('hope', 1), ('milk', 1), ('today', 1), ('enough', 1), ('sudan', 1), ('atieno', 1), ('chang', 1), ('hear', 1), ('hospit', 1), ('jack', 1), ('lesson', 1), ('mobil', 1), ('partner', 1), ('prepar', 1), ('babi', 1), ('beauti', 1), ('birthday', 1), ('cotton', 1), ('find', 1), ('harri', 1), ('shop', 1), ('st', 1), ('market', 1), ('xavier', 1), ('differ', 1), ('eat', 1), ('flat', 1), ('groom', 1), ('howev', 1), ('lot', 1), ('mr', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Example word lists (assuming male_300 and female_300 are defined as strings)\n",
    "mwords = male_300.split()  # Male words\n",
    "fwords = female_300.split()  # Female words\n",
    "\n",
    "# Filtered words for male\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)\n",
    "print(\"Top 40 Male Words:\", topMwords)\n",
    "\n",
    "# Filtered words for female\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)\n",
    "print(\"Top 40 Female Words:\", topFwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9f779-7f69-4213-91cf-3429f1446bbf",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbdfc427-8744-4c54-ba73-fc4c9820b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Female:\n",
      "        Word  FemaleImportance\n",
      "276   atieno               1.0\n",
      "3514  spider               1.0\n",
      "924    dawit               1.0\n",
      "3783    ther               1.0\n",
      "4258  xavier               1.0\n",
      "2097    ladi               1.0\n",
      "3438   smart               1.0\n",
      "1743    hink               1.0\n",
      "3727   teach               1.0\n",
      "2307  market               1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 1]  # Probability of being female\n",
    "female_contributions = np.dot(X.T.toarray(), proba)\n",
    "female_importance = female_contributions / np.sum(X.toarray(), axis=0)\n",
    "female_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"FemaleImportance\": female_importance\n",
    "}).sort_values(by=\"FemaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Female:\")\n",
    "print(female_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e753bf-6df0-45a0-8ec0-d4b191ff4127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Male:\n",
      "          Word  MaleImportance\n",
      "2038     kanja             1.0\n",
      "500   brethren             1.0\n",
      "2288   mandela             1.0\n",
      "2234      lord             1.0\n",
      "26      access             1.0\n",
      "152   although             1.0\n",
      "4210    wizard             1.0\n",
      "620       cave             1.0\n",
      "2261    luther             1.0\n",
      "4011     unoka             1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 0]  # Probability of being male (class 0)\n",
    "\n",
    "\n",
    "male_contributions = np.dot(X.T.toarray(), proba)\n",
    "male_importance = male_contributions / np.sum(X.toarray(), axis=0)\n",
    "male_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"MaleImportance\": male_importance\n",
    "}).sort_values(by=\"MaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Male:\")\n",
    "print(male_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65eaaecb-a8fb-489c-b839-8eb044ce9925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menParaOriginal for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenParaOriginal for item in sublist]))\n",
    "ps = PorterStemmer()\n",
    "words = word_tokenize(fw)\n",
    "matching = [word for word in words if ps.stem(word) in {\"cass\", \"aborigin\",\"sungen\"}]\n",
    "matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
