{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f501497",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd46b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "def pdf_extract(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4930a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the PDF files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put them into a list\n",
    "textbooks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940655ab",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a070bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_lower(post):\n",
    "    if detect(post) != 'en':\n",
    "        return ''\n",
    "    # Make posts lowercase\n",
    "    post = post.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    post = re.sub(r'[^a-zA-Z\\s]', ' ', post)\n",
    "    \n",
    "    # Remove words with repeated letters\n",
    "    #post = re.sub(r'([a-zA-Z])\\1+', r'\\1', post)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(post)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTextbooks = []\n",
    "for i in textbooks:\n",
    "    cleanTextbooks.append(clean_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These have spaces, we use these to select the male and female words\n",
    "menWords = [\" man \", \" boy \", \" male \", \" brother \", \" father \", \" son \", \" husband \", \" king \", \" prince \", \" uncle \", \" nephew \", \" he \", \" him \", \" his \", \" gentleman \", \" sir \", \" mr. \", \" hero \", \" lord \", \" patriarch \", \" men \"]\n",
    "womenWords = [\" woman \", \" girl \", \" female \", \" sister \", \" mother \", \" daughter \", \" wife \", \" queen \", \" princess \", \" aunt \", \" niece \", \" she \", \" her \", \" hers \", \" lady \", \" ma'am \",\" madam \", \" mrs. \", \" ms. \", \" miss \", \" heroine \", \" dame \", \" matriarch \", \" women \"]\n",
    "#These have no spaces, so these can be used to throw away words during TFIDF\n",
    "menWordsNoSpace = [\"man\", \"boy\", \"male\", \"brother\", \"father\", \"son\", \"husband\", \"king\", \"prince\", \"uncle\", \"nephew\", \"he\", \"him\", \"his\", \"gentleman\", \"sir\", \"mr\", \"hero\", \"lord\", \"patriarch\", \"men\"]\n",
    "womenWordsNoSpace = [\"woman\", \"girl\", \"female\", \"sister\", \"mother\", \"daughter\", \"wife\", \"queen\", \"princess\", \"aunt\", \"niece\", \"she\", \"her\", \"hers\", \"lady\", \"ma'am\",\"madam\", \"mrs\", \"heroine\", \"dame\", \"matriarch\", \"women\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "menPara = [[] for _ in range(18)]\n",
    "womenPara = [[] for _ in range(18)]\n",
    "for i in range(0, 18):\n",
    "    text = cleanTextbooks[i]\n",
    "    paragraphs = [text[j:j+100] for j in range(0, len(text), 100)]\n",
    "    for paragraph in paragraphs:\n",
    "        for j in menWords:\n",
    "            if j in paragraph:\n",
    "                menPara[i].append(paragraph)\n",
    "        for j in womenWords:\n",
    "            if j in paragraph:\n",
    "                womenPara[i].append(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f593530",
   "metadata": {},
   "source": [
    "# Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "men_count = sum(len(sublist) for sublist in menPara)\n",
    "print(men_count)\n",
    "women_count = sum(len(sublist) for sublist in womenPara)\n",
    "print(women_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efdc49",
   "metadata": {},
   "source": [
    "# Firstness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd283bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "femaleFirst = []\n",
    "for paragraph in womenPara:\n",
    "    words = paragraph.split()  # Split paragraph into words\n",
    "    for i in range(len(words) - 1):  # Iterate up to the second last word\n",
    "        if words[i].lower() in womenWordsNoSpace and words[i + 1].lower() in menWordsNoSpace:\n",
    "            femaleFirst.append(words[i] + ' ' + words[i + 1])\n",
    "print(len(femaleFirst),femaleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ee8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "maleFirst = []\n",
    "for paragraph in menPara:\n",
    "    words = paragraph.split()  \n",
    "    for i in range(len(words) - 1):  \n",
    "        if words[i].lower() in menWordsNoSpace and words[i + 1].lower() in womenWordsNoSpace:\n",
    "            maleFirst.append(words[i] + ' ' + words[i + 1])\n",
    "print(len(maleFirst),maleFirst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a500d7",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word',\n",
    "                        sublinear_tf=False,\n",
    "                        max_features=500,\n",
    "                        tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c66a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf_men = tfidf.fit(cleanMenParaList)\n",
    "inds = np.argsort(tfidf.idf_)[::-1][:100]\n",
    "top_IDF_tokens_men = [list(tfidf.vocabulary_)[ind] for ind in inds]\n",
    "top_IDF_scores_men = tfidf.idf_[inds]\n",
    "print(top_IDF_tokens_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf_women = tfidf.fit(cleanWomenParaList)\n",
    "inds = np.argsort(tfidf.idf_)[::-1][:100]\n",
    "top_IDF_tokens_women = [list(tfidf.vocabulary_)[ind] for ind in inds]\n",
    "top_IDF_scores_women = tfidf.idf_[inds]\n",
    "print(top_IDF_tokens_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pos_dict_men = {}\n",
    "pos_dict_women={}\n",
    "\n",
    "def get_pos(word):\n",
    "    # Process the word with spaCy\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        return token.text, token.pos_\n",
    "\n",
    "for i in top_IDF_tokens_men:\n",
    "    result = get_pos(i)\n",
    "    pos = result[1]  # POS tag\n",
    "    word_text = result[0]\n",
    "    \n",
    "    # Add word to the list for its POS in the dictionary\n",
    "    if pos not in pos_dict_men:\n",
    "        pos_dict_men[pos] = []\n",
    "    pos_dict_men[pos].append(word_text)\n",
    "\n",
    "for i in top_IDF_tokens_women:\n",
    "    result = get_pos(i)\n",
    "    pos = result[1]  # POS tag\n",
    "    word_text = result[0]\n",
    "    \n",
    "    # Add word to the list for its POS in the dictionary\n",
    "    if pos not in pos_dict_women:\n",
    "        pos_dict_women[pos] = []\n",
    "    pos_dict_women[pos].append(word_text)\n",
    "\n",
    "# Print each POS category and its list of words\n",
    "include_pos = {\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"}\n",
    "for pos, words in pos_dict_men.items():\n",
    "    if pos in include_pos:  \n",
    "        print(f\"{pos}: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6756faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, words in pos_dict_women.items():\n",
    "    if pos in include_pos:  \n",
    "        print(f\"{pos}: {words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
