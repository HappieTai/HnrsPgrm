{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db67ba19-129b-4485-b5f8-7737f1eb8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "def pdf_extract(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "saudi = pdf_extract('saudi/Saudi_7.pdf')+\" \"+ pdf_extract('saudi/Saudi_8.pdf')+\" \"+ pdf_extract('saudi/Saudi_9.pdf')\n",
    "iran = pdf_extract('iran/iran_7.pdf')+\" \"+ pdf_extract('iran/iran_8.pdf')+\" \"+pdf_extract('iran/iran_9.pdf')\n",
    "tun = pdf_extract('Tunisia/Tun_7.pdf')+\" \"+pdf_extract('Tunisia/Tun_8.pdf')+\" \"+pdf_extract('Tunisia/Tun_9.pdf')\n",
    "uzi = pdf_extract('Uzbekistan/Uzi_7.pdf')+\" \"+pdf_extract('Uzbekistan/Uzi_9.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e0eb76-c444-4655-a00e-c71efa2b5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbooks = [saudi, iran, tun, uzi]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698d9f-9282-4938-9e6b-bdbbb58f3707",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c731351b-f590-47fd-a2da-141307297ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048f653e-08fd-4854-9363-111be2beac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(post):\n",
    "    if detect(post) != 'en':\n",
    "        return ''\n",
    "    # Make posts lowercase\n",
    "    post = post.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    post = re.sub(r'[^a-zA-Z\\s]', ' ', post)\n",
    "    \n",
    "    # Remove words with repeated letters\n",
    "    #post = re.sub(r'([a-zA-Z])\\1+', r'\\1', post)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(post)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26899fb3-3fcb-4e08-a820-846fc13be753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTextbooks = []\n",
    "for i in textbooks:\n",
    "    cleanTextbooks.append(clean_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0865f5-c5a6-4171-b347-e2f7d84c1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These have spaces, we use these to select the male and female words\n",
    "menWords = [\" man \", \" boy \", \" male \", \" brother \", \" father \", \" son \", \" husband \", \" king \", \" prince \", \" uncle \", \" nephew \", \" he \", \" him \", \" his \", \" gentleman \", \" sir \", \" mr. \", \" hero \", \" lord \", \" patriarch \", \" men \"]\n",
    "womenWords = [\" woman \", \" girl \", \" female \", \" sister \", \" mother \", \" daughter \", \" wife \", \" queen \", \" princess \", \" aunt \", \" niece \", \" she \", \" her \", \" hers \", \" lady \", \" ma'am \",\" madam \", \" mrs. \", \" ms. \", \" miss \", \" heroine \", \" dame \", \" matriarch \", \" women \"]\n",
    "#These have no spaces, so these can be used to throw away words during TFIDF\n",
    "menWordsNoSpace = [\"man\", \"boy\", \"male\", \"brother\", \"father\", \"son\", \"husband\", \"king\", \"prince\", \"uncle\", \"nephew\", \"he\", \"him\", \"his\", \"gentleman\", \"sir\", \"mr\", \"hero\", \"lord\", \"patriarch\", \"men\"]\n",
    "womenWordsNoSpace = [\"woman\", \"girl\", \"female\", \"sister\", \"mother\", \"daughter\", \"wife\", \"queen\", \"princess\", \"aunt\", \"niece\", \"she\", \"her\", \"hers\", \"lady\", \"ma'am\",\"madam\", \"mrs\", \"heroine\", \"dame\", \"matriarch\", \"women\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "290d69e4-4333-40ca-87ba-568c25c479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "menPara = [[] for _ in range(4)]\n",
    "womenPara = [[] for _ in range(4)]\n",
    "for i in range(0, 4):\n",
    "    text = cleanTextbooks[i]\n",
    "    paragraphs = [text[j:j+100] for j in range(0, len(text), 100)]\n",
    "    for paragraph in paragraphs:\n",
    "        for j in menWords:\n",
    "            if j in paragraph:\n",
    "                menPara[i].append(paragraph)\n",
    "        for j in womenWords:\n",
    "            if j in paragraph:\n",
    "                womenPara[i].append(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244f6af-3406-4451-90f3-cc6888590dcc",
   "metadata": {},
   "source": [
    "# Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2334899-c275-4195-8f8a-e04226d6e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "men_count = sum(len(sublist) for sublist in menPara)\n",
    "print(men_count)\n",
    "women_count = sum(len(sublist) for sublist in womenPara)\n",
    "print(women_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2fb31-e585-4ab5-b235-8fef226dbcba",
   "metadata": {},
   "source": [
    "# Firstness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc06c38f-9e71-45fe-8d94-c76c27ae5545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 [('mother', 'brother'), ('mother', 'brother'), ('sister', 'father'), ('sister', 'father'), ('mother', 'father'), ('girl', 'boy'), ('mother', 'father'), ('queen', 'prince'), ('wife', 'husband'), ('mother', 'father'), ('mother', 'father')]\n"
     ]
    }
   ],
   "source": [
    "femaleFirst = []\n",
    "for sublist in womenPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1): \n",
    "                if words[i].lower() in womenWordsNoSpace and words[i + 1].lower() in menWordsNoSpace:\n",
    "                    femaleFirst.append((words[i], words[i + 1]))\n",
    "print(len(femaleFirst),femaleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b2b3f0a-1032-438d-a825-8a96727a06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 [('father', 'mother'), ('father', 'mother'), ('father', 'mother'), ('brother', 'sister'), ('father', 'mother'), ('brother', 'sister'), ('father', 'mother'), ('brother', 'sister'), ('brother', 'sister'), ('brother', 'sister'), ('brother', 'sister'), ('men', 'women'), ('men', 'women'), ('king', 'queen'), ('male', 'female'), ('boy', 'girl'), ('boy', 'girl'), ('boy', 'girl'), ('father', 'mother'), ('father', 'mother'), ('brother', 'sister'), ('men', 'women'), ('men', 'women'), ('men', 'women'), ('father', 'mother'), ('boy', 'girl'), ('uncle', 'aunt'), ('uncle', 'aunt')]\n"
     ]
    }
   ],
   "source": [
    "maleFirst = []\n",
    "for sublist in menPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1):  \n",
    "                if words[i].lower() in menWordsNoSpace and words[i + 1].lower() in womenWordsNoSpace:\n",
    "                    maleFirst.append((words[i], words[i + 1]))\n",
    "print(len(maleFirst),maleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af37994e-05be-412d-9bb3-04d6d55624ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameLevel = {\n",
    "    \"siblings\": {\"brother\", \"sister\"},\n",
    "    \"parent_child\": {\"father\", \"mother\", \"son\", \"daughter\"},\n",
    "    \"spouses\": {\"husband\", \"wife\"},\n",
    "    \"royalty\": {\"king\", \"queen\", \"prince\", \"princess\"},\n",
    "    \"extended_family\": {\"uncle\", \"aunt\", \"nephew\", \"niece\"},\n",
    "    \"personal_pronouns\": {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"},\n",
    "    \"titles\": {\"gentleman\", \"lady\", \"sir\", \"ma'am\", \"mr\", \"mrs\", \"madam\"},\n",
    "    \"heroic_roles\": {\"hero\", \"heroine\"},\n",
    "    \"social_roles\": {\"patriarch\", \"matriarch\"},\n",
    "    \"general_plural\": {\"men\", \"women\"},\n",
    "}\n",
    "flat = {word for group in sameLevel.values() for word in group}\n",
    "def isSame(pair):\n",
    "    return pair[0] in flat and pair[1] in flat\n",
    "femaleFirst = [pair for pair in femaleFirst if isSame(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfbab8b1-a034-45fb-b4bb-ed631ff7bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "maleFirst = [pair for pair in maleFirst if isSame(pair)]\n",
    "print(len(maleFirst))\n",
    "print(len(femaleFirst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42749a-7ebd-4437-a0c0-41fc656e0b60",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bb0da50-bff0-4643-8b34-a47567b2d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.08, 'neu': 0.742, 'pos': 0.178, 'compound': 0.9999} {'neg': 0.061, 'neu': 0.774, 'pos': 0.166, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "fscores = analyzer.polarity_scores(fw)\n",
    "mscores = analyzer.polarity_scores(fm)\n",
    "print(fscores,mscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f4b6-b38a-4060-b0d6-6cb38e185d86",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b92c3597-3e9b-43c2-9309-060dc953377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46939507-4cb2-4878-bf59-dd490ff40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_nested_list(nested_list):\n",
    "    return [\n",
    "        [\n",
    "            ' '.join(stemmer.stem(word) for word in sentence.split())\n",
    "            for sentence in sublist\n",
    "        ]\n",
    "        for sublist in nested_list\n",
    "    ]\n",
    "menParaOriginal = menPara\n",
    "womenParaOriginal = womenPara\n",
    "menPara = stem_nested_list(menPara)\n",
    "womenPara = stem_nested_list(womenPara)\n",
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0455810b-6118-4b49-9f9b-fad88d160e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobeTFIDF = [\" \".join(\" \".join(row) for row in menPara),\" \".join(\" \".join(row) for row in womenPara)]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tobeTFIDF)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_tfidf = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41496c61-bcae-47b8-bd80-93cd15193b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of female words\n",
    "doc_index = 1\n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores = sorted(word_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_fs = sorted_word_scores[:300]\n",
    "top_300_words_f = [word for word, score in sorted_word_scores[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3180e23a-9366-4c8a-8ea8-7f0614e5a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of male words\n",
    "doc_index = 0  \n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs_m = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores_m = sorted(word_score_pairs_m, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_ms = sorted_word_scores_m[:300]\n",
    "top_300_words_m = [word for word, score in sorted_word_scores_m[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7caf800-9276-4c28-b948-7fe71e47ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove common words and gendered keywords\n",
    "common = list(set(top_300_words_f) & set(top_300_words_m))\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in common]\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in womenWordsNoSpace]\n",
    "female_300 = \" \".join(top_300_words_f)\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in common]\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in menWordsNoSpace]\n",
    "male_300 = \" \".join(top_300_words_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359c200d-8b7e-4d88-9768-d95d1ecf33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss translat nanci tongu countri must enjoy hate dear tabl angri bought tea come everi mom rememb stay turn hear ladi adj championship show bad beauti chore dad elizabeth futur ii kind list three wonder afraid cool gave gymnast march share unhappi celebr colleg competit cost decid finish gap high ice much programm sabah sever smoke stand statu street togeth usual uzbekistan weekend worri yesterday along anyon boss claus dynasti flower insid interview milk mo natali nd ning program remot rniga role third unkind window wrist aisha babi buy care cold complaint constitut correct cream england english even food form gener grade holiday housework hurt lenient market minut modul pair palac point present price pronunci pupil rel repair royal small someon speak still teen th tooth un verb adel age arriv bag ball belong breakfast britain british buckingham comfort convers differ dress eat edu elder\n",
      "sg combo ali watch uncl drive next saw littl adject nemo phone sit doctor run ahm back put albrecht believ cell friendli hors joe tourist charl nation store student taxi albert histori side test becom game happi never offic park pocket unit young activ adnan ever exampl fahd learn need paper room saeed shirt thank titl wear william academi bank bench career direct driver eye fals fine logan middl near olymp page race ride saudi toy also anoth anthem began colour comprehens famou karat let life lost morn often pack paint partner rain short sound suit sure swim team thought tom tri alreadi anim arabia art artist ather ay backpack becam bed bore brochur choic cousin cup danni dish exchang film free fulfil full ground hit iti jameel joke jump karshi lake lunch mad matter monday newspap nice nuremberg open order past prep rashid river\n"
     ]
    }
   ],
   "source": [
    "print(female_300)\n",
    "print(male_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02bb46d5-079f-4682-8bb8-a609b125e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "mwords = male_300.split()\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb6e9164-4aaf-4e46-9cb0-818099905043",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwords = female_300.split()\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad186a1a-666b-4bc3-89f8-fb43847cfc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Male Words: [('sg', 1), ('combo', 1), ('ali', 1), ('watch', 1), ('uncl', 1), ('drive', 1), ('next', 1), ('saw', 1), ('littl', 1), ('adject', 1), ('nemo', 1), ('phone', 1), ('sit', 1), ('doctor', 1), ('run', 1), ('ahm', 1), ('back', 1), ('put', 1), ('albrecht', 1), ('believ', 1), ('cell', 1), ('friendli', 1), ('hors', 1), ('joe', 1), ('tourist', 1), ('charl', 1), ('nation', 1), ('store', 1), ('student', 1), ('taxi', 1), ('albert', 1), ('histori', 1), ('side', 1), ('test', 1), ('becom', 1), ('game', 1), ('happi', 1), ('never', 1), ('offic', 1), ('park', 1)]\n",
      "Top 40 Female Words: [('miss', 1), ('translat', 1), ('nanci', 1), ('tongu', 1), ('countri', 1), ('must', 1), ('enjoy', 1), ('hate', 1), ('dear', 1), ('tabl', 1), ('angri', 1), ('bought', 1), ('tea', 1), ('come', 1), ('everi', 1), ('mom', 1), ('rememb', 1), ('stay', 1), ('turn', 1), ('hear', 1), ('ladi', 1), ('adj', 1), ('championship', 1), ('show', 1), ('bad', 1), ('beauti', 1), ('chore', 1), ('dad', 1), ('elizabeth', 1), ('futur', 1), ('ii', 1), ('kind', 1), ('list', 1), ('three', 1), ('wonder', 1), ('afraid', 1), ('cool', 1), ('gave', 1), ('gymnast', 1), ('march', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Example word lists (assuming male_300 and female_300 are defined as strings)\n",
    "mwords = male_300.split()  # Male words\n",
    "fwords = female_300.split()  # Female words\n",
    "\n",
    "# Filtered words for male\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)\n",
    "print(\"Top 40 Male Words:\", topMwords)\n",
    "\n",
    "# Filtered words for female\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)\n",
    "print(\"Top 40 Female Words:\", topFwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9f779-7f69-4213-91cf-3429f1446bbf",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbdfc427-8744-4c54-ba73-fc4c9820b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Female:\n",
      "          Word  FemaleImportance\n",
      "1018      ladi               1.0\n",
      "1180      miss               1.0\n",
      "1901     tongu               1.0\n",
      "573      enjoy               1.0\n",
      "95       angri               1.0\n",
      "828       hate               1.0\n",
      "1921  translat               1.0\n",
      "1220     nanci               1.0\n",
      "1834       tea               1.0\n",
      "244     bought               1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 1]  # Probability of being female\n",
    "female_contributions = np.dot(X.T.toarray(), proba)\n",
    "female_importance = female_contributions / np.sum(X.toarray(), axis=0)\n",
    "female_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"FemaleImportance\": female_importance\n",
    "}).sort_values(by=\"FemaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Female:\")\n",
    "print(female_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41e753bf-6df0-45a0-8ec0-d4b191ff4127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Male:\n",
      "          Word  MaleImportance\n",
      "1915       toy             1.0\n",
      "1674      side             1.0\n",
      "1242      nemo             1.0\n",
      "1331      page             1.0\n",
      "26      adject             1.0\n",
      "61         ali             1.0\n",
      "310       cell             1.0\n",
      "965        joe             1.0\n",
      "869       hors             1.0\n",
      "59    albrecht             1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 0]  # Probability of being male (class 0)\n",
    "\n",
    "\n",
    "male_contributions = np.dot(X.T.toarray(), proba)\n",
    "male_importance = male_contributions / np.sum(X.toarray(), axis=0)\n",
    "male_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"MaleImportance\": male_importance\n",
    "}).sort_values(by=\"MaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Male:\")\n",
    "print(male_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65eaaecb-a8fb-489c-b839-8eb044ce9925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menParaOriginal for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenParaOriginal for item in sublist]))\n",
    "ps = PorterStemmer()\n",
    "words = word_tokenize(fw)\n",
    "matching = [word for word in words if ps.stem(word) in {\"cass\", \"aborigin\",\"sungen\"}]\n",
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15cc509-6b15-4380-9db3-f3d86e7c8041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
