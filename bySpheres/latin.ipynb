{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db67ba19-129b-4485-b5f8-7737f1eb8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "def pdf_extract(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "with open('mexico/Mexico_7.txt','r', encoding = 'utf-8', errors = 'ignore') as file:\n",
    "    mexico_7 = file.read()\n",
    "with open('mexico/Mexico_8.txt','r', encoding = 'utf-8', errors = 'ignore') as file:\n",
    "    mexico_8 = file.read()\n",
    "mex = mexico_7 +\" \"+ mexico_8\n",
    "sc = pdf_extract('southernCone/sc_co_7.pdf')+\" \"+pdf_extract('southernCone/sc_ft_8.pdf')+\" \"+pdf_extract('southernCone/sc_ft_9.pdf')+\" \"+pdf_extract('southernCone/sc_nh_8.pdf')+\" \"+pdf_extract('southernCone/sc_nh_9.pdf')+\" \"+pdf_extract('southernCone/sc_no_7.pdf')+\" \"+pdf_extract('southernCone/sc_no_8.pdf')+\" \"+pdf_extract('southernCone/sc_no_9.pdf')+\" \"+pdf_extract('southernCone/sc_ps_7.pdf')+\" \"+pdf_extract('southernCone/sc_ss_7.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e0eb76-c444-4655-a00e-c71efa2b5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "textbooks = [mex, sc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698d9f-9282-4938-9e6b-bdbbb58f3707",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c731351b-f590-47fd-a2da-141307297ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048f653e-08fd-4854-9363-111be2beac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(post):\n",
    "    if detect(post) != 'en':\n",
    "        return ''\n",
    "    # Make posts lowercase\n",
    "    post = post.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    post = re.sub(r'[^a-zA-Z\\s]', ' ', post)\n",
    "    \n",
    "    # Remove words with repeated letters\n",
    "    #post = re.sub(r'([a-zA-Z])\\1+', r'\\1', post)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(post)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26899fb3-3fcb-4e08-a820-846fc13be753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTextbooks = []\n",
    "for i in textbooks:\n",
    "    cleanTextbooks.append(clean_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0865f5-c5a6-4171-b347-e2f7d84c1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These have spaces, we use these to select the male and female words\n",
    "menWords = [\" man \", \" boy \", \" male \", \" brother \", \" father \", \" son \", \" husband \", \" king \", \" prince \", \" uncle \", \" nephew \", \" he \", \" him \", \" his \", \" gentleman \", \" sir \", \" mr. \", \" hero \", \" lord \", \" patriarch \", \" men \"]\n",
    "womenWords = [\" woman \", \" girl \", \" female \", \" sister \", \" mother \", \" daughter \", \" wife \", \" queen \", \" princess \", \" aunt \", \" niece \", \" she \", \" her \", \" hers \", \" lady \", \" ma'am \",\" madam \", \" mrs. \", \" ms. \", \" miss \", \" heroine \", \" dame \", \" matriarch \", \" women \"]\n",
    "#These have no spaces, so these can be used to throw away words during TFIDF\n",
    "menWordsNoSpace = [\"man\", \"boy\", \"male\", \"brother\", \"father\", \"son\", \"husband\", \"king\", \"prince\", \"uncle\", \"nephew\", \"he\", \"him\", \"his\", \"gentleman\", \"sir\", \"mr\", \"hero\", \"lord\", \"patriarch\", \"men\"]\n",
    "womenWordsNoSpace = [\"woman\", \"girl\", \"female\", \"sister\", \"mother\", \"daughter\", \"wife\", \"queen\", \"princess\", \"aunt\", \"niece\", \"she\", \"her\", \"hers\", \"lady\", \"ma'am\",\"madam\", \"mrs\", \"heroine\", \"dame\", \"matriarch\", \"women\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290d69e4-4333-40ca-87ba-568c25c479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "menPara = [[] for _ in range(2)]\n",
    "womenPara = [[] for _ in range(2)]\n",
    "for i in range(0, 2):\n",
    "    text = cleanTextbooks[i]\n",
    "    paragraphs = [text[j:j+100] for j in range(0, len(text), 100)]\n",
    "    for paragraph in paragraphs:\n",
    "        for j in menWords:\n",
    "            if j in paragraph:\n",
    "                menPara[i].append(paragraph)\n",
    "        for j in womenWords:\n",
    "            if j in paragraph:\n",
    "                womenPara[i].append(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244f6af-3406-4451-90f3-cc6888590dcc",
   "metadata": {},
   "source": [
    "# Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2334899-c275-4195-8f8a-e04226d6e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n",
      "914\n"
     ]
    }
   ],
   "source": [
    "men_count = sum(len(sublist) for sublist in menPara)\n",
    "print(men_count)\n",
    "women_count = sum(len(sublist) for sublist in womenPara)\n",
    "print(women_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2fb31-e585-4ab5-b235-8fef226dbcba",
   "metadata": {},
   "source": [
    "# Firstness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc06c38f-9e71-45fe-8d94-c76c27ae5545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 [('woman', 'man'), ('woman', 'boy'), ('girl', 'man'), ('wife', 'prince'), ('wife', 'prince'), ('mother', 'son'), ('daughter', 'father'), ('mother', 'son'), ('daughter', 'father'), ('mother', 'brother'), ('mother', 'father'), ('mother', 'men'), ('mother', 'men'), ('mother', 'brother'), ('girl', 'boy'), ('sister', 'son'), ('daughter', 'brother'), ('daughter', 'son'), ('daughter', 'father'), ('sister', 'son'), ('daughter', 'brother'), ('daughter', 'son'), ('daughter', 'father'), ('sister', 'son'), ('daughter', 'brother'), ('daughter', 'son'), ('daughter', 'father'), ('lady', 'uncle'), ('lady', 'uncle'), ('mother', 'uncle'), ('mother', 'father'), ('sister', 'son'), ('girl', 'boy'), ('girl', 'boy'), ('woman', 'man'), ('women', 'men'), ('woman', 'man'), ('women', 'men'), ('mother', 'father'), ('sister', 'brother'), ('mother', 'father'), ('girl', 'boy'), ('daughter', 'father'), ('mother', 'son'), ('wife', 'husband'), ('mother', 'son'), ('wife', 'husband'), ('mother', 'father'), ('sister', 'son'), ('sister', 'son'), ('sister', 'son'), ('sister', 'uncle'), ('mother', 'father'), ('aunt', 'brother'), ('sister', 'uncle'), ('sister', 'uncle'), ('woman', 'man'), ('niece', 'brother'), ('daughter', 'king'), ('queen', 'son'), ('niece', 'brother'), ('daughter', 'king'), ('queen', 'son'), ('niece', 'brother'), ('daughter', 'king'), ('queen', 'son'), ('niece', 'brother'), ('daughter', 'king'), ('queen', 'son'), ('women', 'men'), ('mother', 'father'), ('mother', 'father'), ('wife', 'husband'), ('mother', 'father'), ('sister', 'father'), ('mother', 'father'), ('girl', 'boy'), ('mother', 'brother'), ('mother', 'brother'), ('sister', 'brother'), ('sister', 'brother'), ('girl', 'brother'), ('girl', 'brother'), ('girl', 'brother'), ('girl', 'brother'), ('girl', 'brother'), ('mother', 'father'), ('sister', 'brother'), ('sister', 'brother'), ('mother', 'father'), ('mother', 'father'), ('wife', 'husband'), ('mother', 'father'), ('wife', 'husband'), ('daughter', 'son'), ('sister', 'brother'), ('mother', 'father'), ('mother', 'brother'), ('sister', 'mr'), ('sister', 'mr'), ('girl', 'boy'), ('girl', 'boy'), ('girl', 'boy'), ('girl', 'boy'), ('sister', 'brother'), ('mother', 'father'), ('mother', 'father')]\n"
     ]
    }
   ],
   "source": [
    "femaleFirst = []\n",
    "for sublist in womenPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1): \n",
    "                if words[i].lower() in womenWordsNoSpace and words[i + 1].lower() in menWordsNoSpace:\n",
    "                    femaleFirst.append((words[i], words[i + 1]))\n",
    "print(len(femaleFirst),femaleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2b3f0a-1032-438d-a825-8a96727a06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 [('boy', 'girl'), ('man', 'woman'), ('man', 'woman'), ('man', 'woman'), ('man', 'woman'), ('boy', 'girl'), ('boy', 'girl'), ('king', 'queen'), ('father', 'mrs'), ('brother', 'wife'), ('brother', 'wife'), ('brother', 'wife'), ('brother', 'wife'), ('men', 'woman'), ('men', 'woman'), ('son', 'daughter'), ('son', 'daughter'), ('uncle', 'aunt'), ('brother', 'sister'), ('uncle', 'aunt'), ('brother', 'sister'), ('uncle', 'aunt'), ('brother', 'sister'), ('father', 'mother'), ('father', 'mother'), ('brother', 'sister'), ('brother', 'sister'), ('men', 'women'), ('brother', 'aunt'), ('men', 'women'), ('men', 'women'), ('men', 'women'), ('father', 'sister'), ('father', 'sister'), ('father', 'sister'), ('nephew', 'niece'), ('nephew', 'niece'), ('nephew', 'niece'), ('nephew', 'niece'), ('father', 'sister'), ('brother', 'daughter'), ('son', 'sister'), ('father', 'mother'), ('father', 'sister'), ('brother', 'daughter'), ('son', 'sister'), ('father', 'mother'), ('father', 'sister'), ('brother', 'daughter'), ('son', 'sister'), ('father', 'mother'), ('father', 'daughter'), ('father', 'daughter'), ('father', 'daughter'), ('father', 'daughter'), ('father', 'daughter'), ('brother', 'aunt'), ('son', 'sister'), ('husband', 'wife'), ('husband', 'wife'), ('husband', 'wife'), ('man', 'woman'), ('man', 'women'), ('man', 'women'), ('men', 'women'), ('boy', 'girl'), ('men', 'women'), ('man', 'woman'), ('brother', 'sister'), ('boy', 'girl'), ('mr', 'mrs'), ('son', 'wife'), ('boy', 'mother'), ('boy', 'mother'), ('brother', 'sister'), ('brother', 'daughter'), ('king', 'wife'), ('brother', 'daughter'), ('king', 'wife'), ('brother', 'daughter'), ('king', 'wife'), ('brother', 'daughter'), ('king', 'wife'), ('boy', 'girl'), ('boy', 'girl'), ('boy', 'girl'), ('sir', 'madam'), ('man', 'girl'), ('man', 'woman'), ('boy', 'girl'), ('male', 'female'), ('sir', 'madam'), ('men', 'women'), ('men', 'women'), ('brother', 'sister'), ('hero', 'heroine'), ('male', 'female'), ('man', 'woman'), ('brother', 'sister'), ('brother', 'sister'), ('brother', 'woman'), ('brother', 'woman'), ('sir', 'madam'), ('man', 'woman'), ('boy', 'sister'), ('boy', 'sister'), ('brother', 'sister'), ('brother', 'sister'), ('men', 'women'), ('men', 'women'), ('brother', 'sister'), ('father', 'mother'), ('brother', 'sister'), ('father', 'mother'), ('brother', 'sister'), ('men', 'women'), ('father', 'mother'), ('father', 'mother'), ('brother', 'girl'), ('brother', 'girl'), ('men', 'woman'), ('men', 'woman'), ('brother', 'sister'), ('son', 'daughter'), ('brother', 'daughter'), ('brother', 'sister'), ('boy', 'girl'), ('boy', 'girl'), ('boy', 'girl'), ('boy', 'girl'), ('brother', 'sister'), ('brother', 'daughter'), ('brother', 'daughter'), ('boy', 'sister'), ('boy', 'sister'), ('boy', 'sister')]\n"
     ]
    }
   ],
   "source": [
    "maleFirst = []\n",
    "for sublist in menPara:  \n",
    "    for paragraph in sublist:  \n",
    "        if isinstance(paragraph, str):  \n",
    "            words = paragraph.split()  \n",
    "            for i in range(len(words) - 1):  \n",
    "                if words[i].lower() in menWordsNoSpace and words[i + 1].lower() in womenWordsNoSpace:\n",
    "                    maleFirst.append((words[i], words[i + 1]))\n",
    "print(len(maleFirst),maleFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af37994e-05be-412d-9bb3-04d6d55624ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameLevel = {\n",
    "    \"siblings\": {\"brother\", \"sister\"},\n",
    "    \"parent_child\": {\"father\", \"mother\", \"son\", \"daughter\"},\n",
    "    \"spouses\": {\"husband\", \"wife\"},\n",
    "    \"royalty\": {\"king\", \"queen\", \"prince\", \"princess\"},\n",
    "    \"extended_family\": {\"uncle\", \"aunt\", \"nephew\", \"niece\"},\n",
    "    \"personal_pronouns\": {\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\"},\n",
    "    \"titles\": {\"gentleman\", \"lady\", \"sir\", \"ma'am\", \"mr\", \"mrs\", \"madam\"},\n",
    "    \"heroic_roles\": {\"hero\", \"heroine\"},\n",
    "    \"social_roles\": {\"patriarch\", \"matriarch\"},\n",
    "    \"general_plural\": {\"men\", \"women\"},\n",
    "}\n",
    "flat = {word for group in sameLevel.values() for word in group}\n",
    "def isSame(pair):\n",
    "    return pair[0] in flat and pair[1] in flat\n",
    "femaleFirst = [pair for pair in femaleFirst if isSame(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbab8b1-a034-45fb-b4bb-ed631ff7bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "maleFirst = [pair for pair in maleFirst if isSame(pair)]\n",
    "print(len(maleFirst))\n",
    "print(len(femaleFirst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42749a-7ebd-4437-a0c0-41fc656e0b60",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bb0da50-bff0-4643-8b34-a47567b2d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.061, 'neu': 0.786, 'pos': 0.153, 'compound': 1.0} {'neg': 0.054, 'neu': 0.798, 'pos': 0.148, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "fscores = analyzer.polarity_scores(fw)\n",
    "mscores = analyzer.polarity_scores(fm)\n",
    "print(fscores,mscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f4b6-b38a-4060-b0d6-6cb38e185d86",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92c3597-3e9b-43c2-9309-060dc953377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46939507-4cb2-4878-bf59-dd490ff40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_nested_list(nested_list):\n",
    "    return [\n",
    "        [\n",
    "            ' '.join(stemmer.stem(word) for word in sentence.split())\n",
    "            for sentence in sublist\n",
    "        ]\n",
    "        for sublist in nested_list\n",
    "    ]\n",
    "menParaOriginal = menPara\n",
    "womenParaOriginal = womenPara\n",
    "menPara = stem_nested_list(menPara)\n",
    "womenPara = stem_nested_list(womenPara)\n",
    "fm = ', '.join(map(str, [item for sublist in menPara for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenPara for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0455810b-6118-4b49-9f9b-fad88d160e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobeTFIDF = [\" \".join(\" \".join(row) for row in menPara),\" \".join(\" \".join(row) for row in womenPara)]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tobeTFIDF)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_tfidf = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41496c61-bcae-47b8-bd80-93cd15193b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of female words\n",
    "doc_index = 1\n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores = sorted(word_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_fs = sorted_word_scores[:300]\n",
    "top_300_words_f = [word for word, score in sorted_word_scores[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3180e23a-9366-4c8a-8ea8-7f0614e5a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf of male words\n",
    "doc_index = 0  \n",
    "doc_tfidf_scores = dense_tfidf[doc_index]\n",
    "word_score_pairs_m = list(zip(feature_names, doc_tfidf_scores))\n",
    "sorted_word_scores_m = sorted(word_score_pairs_m, key=lambda x: x[1], reverse=True)\n",
    "top_300_words_ms = sorted_word_scores_m[:300]\n",
    "top_300_words_m = [word for word, score in sorted_word_scores_m[:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7caf800-9276-4c28-b948-7fe71e47ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove common words and gendered keywords\n",
    "common = list(set(top_300_words_f) & set(top_300_words_m))\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in common]\n",
    "top_300_words_f = [word for word in top_300_words_f if word not in womenWordsNoSpace]\n",
    "female_300 = \" \".join(top_300_words_f)\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in common]\n",
    "top_300_words_m = [word for word in top_300_words_m if word not in menWordsNoSpace]\n",
    "male_300 = \" \".join(top_300_words_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "359c200d-8b7e-4d88-9768-d95d1ecf33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verb visit tv parti stay femal london song yesterday adam becam french laura ms ng run bishop bore cat elizabeth grammar much niec today whose form star usual dinner gabriela ghost ok possess se vocabulari sue alway band beauti cold feel jack jean ladi mobil monday sit tire afraid ago also american chri co cours differ green happi interest mall mari member part restaur si usa adj america bedroom better britain convers de earli ever fisherman gave hen holiday jami\n",
      "richard kill robin sheriff dorian studi ar group hot polic episod ten toni twenti box dictionari favourit morion wash away en noun ond order toke alfr da feminin inin masculin inform meet peter robert sea sorri st wo wont would friar tuck aid buy describ footbal hamlet happen la learn na radio somebodi stop tree william becom bill bo citi colleg fals game ing jane note open prison sound street swim sybil huntingdon om sherwood angri bank\n"
     ]
    }
   ],
   "source": [
    "print(female_300)\n",
    "print(male_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02bb46d5-079f-4682-8bb8-a609b125e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "mwords = male_300.split()\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb6e9164-4aaf-4e46-9cb0-818099905043",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwords = female_300.split()\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad186a1a-666b-4bc3-89f8-fb43847cfc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Male Words: [('richard', 1), ('kill', 1), ('robin', 1), ('sheriff', 1), ('dorian', 1), ('studi', 1), ('ar', 1), ('group', 1), ('hot', 1), ('polic', 1), ('episod', 1), ('ten', 1), ('toni', 1), ('twenti', 1), ('box', 1), ('dictionari', 1), ('favourit', 1), ('morion', 1), ('wash', 1), ('away', 1), ('en', 1), ('noun', 1), ('ond', 1), ('order', 1), ('toke', 1), ('alfr', 1), ('da', 1), ('feminin', 1), ('inin', 1), ('masculin', 1), ('inform', 1), ('meet', 1), ('peter', 1), ('robert', 1), ('sea', 1), ('sorri', 1), ('st', 1), ('wo', 1), ('wont', 1), ('would', 1)]\n",
      "Top 40 Female Words: [('verb', 1), ('visit', 1), ('tv', 1), ('parti', 1), ('stay', 1), ('femal', 1), ('london', 1), ('song', 1), ('yesterday', 1), ('adam', 1), ('becam', 1), ('french', 1), ('laura', 1), ('ms', 1), ('ng', 1), ('run', 1), ('bishop', 1), ('bore', 1), ('cat', 1), ('elizabeth', 1), ('grammar', 1), ('much', 1), ('niec', 1), ('today', 1), ('whose', 1), ('form', 1), ('star', 1), ('usual', 1), ('dinner', 1), ('gabriela', 1), ('ghost', 1), ('ok', 1), ('possess', 1), ('se', 1), ('vocabulari', 1), ('sue', 1), ('alway', 1), ('band', 1), ('beauti', 1), ('cold', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Example word lists (assuming male_300 and female_300 are defined as strings)\n",
    "mwords = male_300.split()  # Male words\n",
    "fwords = female_300.split()  # Female words\n",
    "\n",
    "# Filtered words for male\n",
    "filteredMwords = [word for word in mwords if word in fm]\n",
    "wordMcounts = Counter(filteredMwords)\n",
    "topMwords = wordMcounts.most_common(40)\n",
    "print(\"Top 40 Male Words:\", topMwords)\n",
    "\n",
    "# Filtered words for female\n",
    "filteredFwords = [word for word in fwords if word in fw]\n",
    "wordFcounts = Counter(filteredFwords)\n",
    "topFwords = wordFcounts.most_common(40)\n",
    "print(\"Top 40 Female Words:\", topFwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9f779-7f69-4213-91cf-3429f1446bbf",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbdfc427-8744-4c54-ba73-fc4c9820b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Female:\n",
      "           Word  FemaleImportance\n",
      "4404      susan          1.000000\n",
      "4373        sue          1.000000\n",
      "4180      smith          1.000000\n",
      "3243      organ          1.000000\n",
      "2764     meadow          1.000000\n",
      "454      bishop          1.000000\n",
      "373       beatl          1.000000\n",
      "2994  neighbour          1.000000\n",
      "3962       save          1.000000\n",
      "743       chink          0.994466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 1]  # Probability of being female\n",
    "female_contributions = np.dot(X.T.toarray(), proba)\n",
    "female_importance = female_contributions / np.sum(X.toarray(), axis=0)\n",
    "female_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"FemaleImportance\": female_importance\n",
    "}).sort_values(by=\"FemaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Female:\")\n",
    "print(female_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e753bf-6df0-45a0-8ec0-d4b191ff4127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words most related to Male:\n",
      "            Word  MaleImportance\n",
      "4555    thursday             1.0\n",
      "1366      episod             1.0\n",
      "4069     sheriff             1.0\n",
      "1653       friar             1.0\n",
      "5075      writer             1.0\n",
      "3649        race             1.0\n",
      "4072    sherwood             1.0\n",
      "2711   mannequin             1.0\n",
      "1520     feminin             1.0\n",
      "2066  huntingdon             1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "male_segments = fm.split(\" \")  \n",
    "female_segments = fw.split(\" \")  \n",
    "texts = male_segments + female_segments  \n",
    "labels = [0] * len(male_segments) + [1] * len(female_segments)  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "X = vectorizer.fit_transform(texts)  \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X, labels)\n",
    "\n",
    "proba = clf.predict_proba(X)[:, 0]  # Probability of being male (class 0)\n",
    "\n",
    "\n",
    "male_contributions = np.dot(X.T.toarray(), proba)\n",
    "male_importance = male_contributions / np.sum(X.toarray(), axis=0)\n",
    "male_importance_df = pd.DataFrame({\n",
    "    \"Word\": feature_names,\n",
    "    \"MaleImportance\": male_importance\n",
    "}).sort_values(by=\"MaleImportance\", ascending=False)\n",
    "\n",
    "print(\"Top words most related to Male:\")\n",
    "print(male_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65eaaecb-a8fb-489c-b839-8eb044ce9925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = ', '.join(map(str, [item for sublist in menParaOriginal for item in sublist]))\n",
    "fw = ', '.join(map(str, [item for sublist in womenParaOriginal for item in sublist]))\n",
    "ps = PorterStemmer()\n",
    "words = word_tokenize(fw)\n",
    "matching = [word for word in words if ps.stem(word) in {\"cass\", \"aborigin\",\"sungen\"}]\n",
    "matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
